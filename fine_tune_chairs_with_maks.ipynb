{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f168d63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nehir/Desktop/psvh_finetuning/.venv/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "üöÄ M4 Pro GPU (Metal) Ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from run_case import real_model \n",
    "# This is the \"Magic Sauce\" for M4 Pro\n",
    "tf.disable_eager_execution()\n",
    "tf.disable_v2_behavior()\n",
    "tf.disable_v2_behavior()\n",
    "tf.reset_default_graph() # Start with a clean slate\n",
    "\n",
    "# Manual mapping to bypass Pylance resolution errors\n",
    "placeholder = tf.placeholder\n",
    "variable_scope = tf.variable_scope\n",
    "\n",
    "# M4 PRO GPU CONFIG\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    try:\n",
    "        for device in gpu_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "        print(\"üöÄ M4 Pro GPU (Metal) Ready\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è GPU setup info: {e}\")\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9542f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success! TensorFlow 1.x logic is working.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "with tf.variable_scope(\"test\"):\n",
    "    p = tf.placeholder(tf.float32, shape=[1])\n",
    "    print(\"‚úÖ Success! TensorFlow 1.x logic is working.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb53640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chair_data_generator(json_path, batch_size=1):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f).get('chair', [])\n",
    "    \n",
    "    while True:\n",
    "        np.random.shuffle(data)\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch_data = data[i:i + batch_size]\n",
    "            b_imgs, b_voxels, b_masks = [], [], []\n",
    "            \n",
    "            for entry in batch_data:\n",
    "                # Load Image\n",
    "                img = cv2.imread(entry['image_path'])\n",
    "                if img is None: continue\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (128, 128)) / 255.0\n",
    "                \n",
    "                # Load Voxels\n",
    "                voxels = np.load(entry['voxel_gt_path']).astype(np.float32)\n",
    "                voxels = voxels.transpose(2, 1, 0)\n",
    "                if voxels.ndim == 4: voxels = np.squeeze(voxels)\n",
    "                \n",
    "                # Load Mask (New)\n",
    "                # Assuming entry['mask_path'] exists in your JSON\n",
    "                mask = cv2.imread(entry['mask_path'], cv2.IMREAD_GRAYSCALE)\n",
    "                mask = cv2.resize(mask, (32, 32)) # Match voxel spatial grid\n",
    "                mask = (mask > 127).astype(np.float32) # Binary 0 or 1\n",
    "                \n",
    "                b_imgs.append(img)\n",
    "                b_voxels.append(voxels)\n",
    "                b_masks.append(mask)\n",
    "            \n",
    "            if len(b_imgs) == batch_size:\n",
    "                yield np.array(b_imgs), np.array(b_voxels), np.array(b_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c370d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH = \"pascal_metadata_training_fixed.json\"\n",
    "EPOCHS = 5\n",
    "STEPS_PER_EPOCH = 200 \n",
    "BATCH_SIZE = 1\n",
    "\n",
    "save_path = \"./finetuned_chair_with_masks_model_learning_rate_1e_4.cptk\"\n",
    "gen = chair_data_generator(JSON_PATH, BATCH_SIZE)\n",
    "learning_rate = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4de6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: chair_01.npy\n",
      "  - Shape: (32, 32, 32)\n",
      "  - Dtype: uint8\n",
      "  - Min Value: 0\n",
      "  - Max Value: 1\n",
      "  - Unique Values: [0 1]\n",
      "------------------------------\n",
      "File: chair_08.npy\n",
      "  - Shape: (32, 32, 32)\n",
      "  - Dtype: uint8\n",
      "  - Min Value: 0\n",
      "  - Max Value: 1\n",
      "  - Unique Values: [0 1]\n",
      "------------------------------\n",
      "File: chair_05.npy\n",
      "  - Shape: (32, 32, 32)\n",
      "  - Dtype: uint8\n",
      "  - Min Value: 0\n",
      "  - Max Value: 1\n",
      "  - Unique Values: [0 1]\n",
      "------------------------------\n",
      "File: chair_05.npy\n",
      "  - Shape: (32, 32, 32)\n",
      "  - Dtype: uint8\n",
      "  - Min Value: 0\n",
      "  - Max Value: 1\n",
      "  - Unique Values: [0 1]\n",
      "------------------------------\n",
      "File: chair_09.npy\n",
      "  - Shape: (32, 32, 32)\n",
      "  - Dtype: uint8\n",
      "  - Min Value: 0\n",
      "  - Max Value: 1\n",
      "  - Unique Values: [0 1]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "with open(\"pascal_metadata_training_fixed.json\", 'r') as f:\n",
    "    data = json.load(f).get('chair', [])\n",
    "# Check the first 5 samples\n",
    "for i in range(min(5, len(data))):\n",
    "    voxel_path = data[i]['voxel_gt_path']\n",
    "    if os.path.exists(voxel_path):\n",
    "        voxels = np.load(voxel_path)\n",
    "        \n",
    "        print(f\"File: {os.path.basename(voxel_path)}\")\n",
    "        print(f\"  - Shape: {voxels.shape}\")\n",
    "        print(f\"  - Dtype: {voxels.dtype}\")\n",
    "        print(f\"  - Min Value: {np.min(voxels)}\")\n",
    "        print(f\"  - Max Value: {np.max(voxels)}\")\n",
    "        print(f\"  - Unique Values: {np.unique(voxels)}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca053f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool1 Tensor(\"voxel/encoder/MaxPool:0\", shape=(1, 64, 64, 96), dtype=float32)\n",
      "pool2 Tensor(\"voxel/encoder/MaxPool_1:0\", shape=(1, 32, 32, 128), dtype=float32)\n",
      "pool3 Tensor(\"voxel/encoder/MaxPool_2:0\", shape=(1, 16, 16, 256), dtype=float32)\n",
      "pool4 Tensor(\"voxel/encoder/MaxPool_3:0\", shape=(1, 8, 8, 256), dtype=float32)\n",
      "pool5 Tensor(\"voxel/encoder/MaxPool_4:0\", shape=(1, 4, 4, 256), dtype=float32)\n",
      "pool6 Tensor(\"voxel/encoder/Mean:0\", shape=(1, 256), dtype=float32)\n",
      "feature Tensor(\"voxel/encoder/MatMul:0\", shape=(1, 1024), dtype=float32)\n",
      "feature_map Tensor(\"voxel/encoder/MaxPool_5:0\", shape=(1, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"voxel/encoder/MatMul:0\", shape=(1, 1024), dtype=float32)\n",
      "Tensor(\"voxel/decoder/Reshape:0\", shape=(1, 1, 1, 1, 1024), dtype=float32)\n",
      "d1 Tensor(\"voxel/decoder/Relu:0\", shape=(1, 4, 4, 4, 256), dtype=float32)\n",
      "d2 Tensor(\"voxel/decoder/Add:0\", shape=(1, 8, 8, 8, 128), dtype=float32)\n",
      "d3 Tensor(\"voxel/decoder/Add_1:0\", shape=(1, 16, 16, 16, 64), dtype=float32)\n",
      "d4 Tensor(\"voxel/decoder/Add_2:0\", shape=(1, 32, 32, 32, 32), dtype=float32)\n",
      "d5 Tensor(\"voxel/decoder/Add_3:0\", shape=(1, 32, 32, 32, 16), dtype=float32)\n",
      "d6 Tensor(\"voxel/decoder/conv3d_transpose_5:0\", shape=(1, 32, 32, 32, 2), dtype=float32)\n",
      "pool1 Tensor(\"mask/encoder/MaxPool:0\", shape=(1, 64, 64, 96), dtype=float32)\n",
      "pool2 Tensor(\"mask/encoder/MaxPool_1:0\", shape=(1, 32, 32, 128), dtype=float32)\n",
      "pool3 Tensor(\"mask/encoder/MaxPool_2:0\", shape=(1, 16, 16, 256), dtype=float32)\n",
      "pool4 Tensor(\"mask/encoder/MaxPool_3:0\", shape=(1, 8, 8, 256), dtype=float32)\n",
      "pool5 Tensor(\"mask/encoder/MaxPool_4:0\", shape=(1, 4, 4, 256), dtype=float32)\n",
      "pool6 Tensor(\"mask/encoder/Mean:0\", shape=(1, 256), dtype=float32)\n",
      "feature Tensor(\"mask/encoder/MatMul:0\", shape=(1, 1024), dtype=float32)\n",
      "feature_map Tensor(\"mask/encoder/MaxPool_5:0\", shape=(1, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"mask/encoder/MaxPool_5:0\", shape=(1, 2, 2, 256), dtype=float32)\n",
      "pool1 Tensor(\"encoder/MaxPool:0\", shape=(1, 64, 64, 96), dtype=float32)\n",
      "pool2 Tensor(\"encoder/MaxPool_1:0\", shape=(1, 32, 32, 128), dtype=float32)\n",
      "pool3 Tensor(\"encoder/MaxPool_2:0\", shape=(1, 16, 16, 256), dtype=float32)\n",
      "pool4 Tensor(\"encoder/MaxPool_3:0\", shape=(1, 8, 8, 256), dtype=float32)\n",
      "pool5 Tensor(\"encoder/MaxPool_4:0\", shape=(1, 4, 4, 256), dtype=float32)\n",
      "pool6 Tensor(\"encoder/Mean:0\", shape=(1, 256), dtype=float32)\n",
      "feature Tensor(\"encoder/MatMul:0\", shape=(1, 1024), dtype=float32)\n",
      "feature_map Tensor(\"encoder/MaxPool_5:0\", shape=(1, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"stack_11:0\", shape=(1, 32, 32, 32, 2), dtype=float32)\n",
      "Tensor(\"refine_encoder/Maximum:0\", shape=(1, 32, 32, 32, 32), dtype=float32)\n",
      "Tensor(\"refine_encoder/Maximum_1:0\", shape=(1, 16, 16, 16, 64), dtype=float32)\n",
      "Tensor(\"refine_encoder/Maximum_2:0\", shape=(1, 8, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"refine_encoder/Maximum_3:0\", shape=(1, 4, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"refine_encoder/Maximum_4:0\", shape=(1, 1, 1, 1, 512), dtype=float32)\n",
      "d1 Tensor(\"refine_decoder/Add:0\", shape=(1, 4, 4, 4, 256), dtype=float32)\n",
      "d2 Tensor(\"refine_decoder/Add_2:0\", shape=(1, 8, 8, 8, 128), dtype=float32)\n",
      "d3 Tensor(\"refine_decoder/Add_4:0\", shape=(1, 16, 16, 16, 64), dtype=float32)\n",
      "d4 Tensor(\"refine_decoder/Add_6:0\", shape=(1, 32, 32, 32, 32), dtype=float32)\n",
      "d5 Tensor(\"refine_decoder/Add_7:0\", shape=(1, 32, 32, 32, 16), dtype=float32)\n",
      "d6 Tensor(\"refine_decoder/Add_8:0\", shape=(1, 32, 32, 32, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-24 22:01:46.580412: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Pro\n",
      "2026-01-24 22:01:46.580434: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 24.00 GB\n",
      "2026-01-24 22:01:46.580441: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 8.88 GB\n",
      "2026-01-24 22:01:46.580457: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2026-01-24 22:01:46.580465: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2026-01-24 22:01:46.605895: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-01-24 22:01:46.625891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Restoring weights from /Users/nehir/Desktop/psvh_model_weights/23501.cptk...\n",
      "INFO:tensorflow:Restoring parameters from /Users/nehir/Desktop/psvh_model_weights/23501.cptk\n",
      "‚úÖ Weights Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "#Clear the background graph to prevent \"Variable already exists\" \n",
    "tf.compat.v1.reset_default_graph()\n",
    "checkpoint_path = \"/Users/nehir/Desktop/psvh_model_weights/23501.cptk\"\n",
    "\n",
    "# 2. Define Model and Tensors\n",
    "# v_after shape: [1, 32, 32, 32]\n",
    "v_before, v_after, img_ph = real_model()\n",
    "gt_ph = tf.compat.v1.placeholder(tf.float32, [None, 32, 32, 32], name=\"vox_gt\")\n",
    "mask_ph = tf.compat.v1.placeholder(tf.float32, [None, 32, 32], name=\"mask_gt\")\n",
    "\n",
    "# --- MASK CONSISTENCY LOSS ---\n",
    "# Project the 3D prediction into 2D by taking the max along the Z-axis\n",
    "# This simulates a \"silhouette\" of the predicted voxels\n",
    "v_projection = tf.reduce_max(v_after, axis=2) \n",
    "\n",
    "# Loss 1: 3D Voxel MSE\n",
    "loss_voxel = tf.reduce_mean(tf.square(v_after - gt_ph))\n",
    "\n",
    "# Loss 2: 2D Mask MSE (The paper's logic)\n",
    "loss_mask = tf.reduce_mean(tf.square(v_projection - mask_ph))\n",
    "\n",
    "# Combined Loss (You can weigh these, e.g., mask might need a higher weight)\n",
    "total_loss = loss_voxel + (1.0 * loss_mask)\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(total_loss)\n",
    "\n",
    "# --- CRITICAL FIX: VARIABLE MANAGEMENT ---\n",
    "\n",
    "# Identify which variables belong to the MODEL (to be restored) \n",
    "# and which belong to the OPTIMIZER (to be initialized)\n",
    "all_vars = tf.compat.v1.global_variables()\n",
    "model_vars = [v for v in all_vars if 'Adam' not in v.name and 'beta' not in v.name]\n",
    "optimizer_vars = [v for v in all_vars if 'Adam' in v.name or 'beta' in v.name]\n",
    "\n",
    "# Create saver for the model weights ONLY\n",
    "saver = tf.compat.v1.train.Saver(var_list=model_vars)\n",
    "\n",
    "# 4. Session Execution\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "# Initialize ONLY the new optimizer variables (so we don't overwrite the model)\n",
    "if optimizer_vars:\n",
    "    sess.run(tf.compat.v1.variables_initializer(optimizer_vars))\n",
    "else:\n",
    "    # Fallback if no optimizer vars found yet\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "print(f\"üì° Restoring weights from {checkpoint_path}...\")\n",
    "try:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    print(\"‚úÖ Weights Loaded Successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Restore failed: {e}\")\n",
    "    print(\"Hint: Check if the checkpoint path is correct or if model architecture changed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb15dd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Name: voxel/encoder/wd00:0\n",
      "Weight Mean: 1.9196944776922464e-05\n",
      "Weight Max: 0.10852489620447159\n",
      "‚úÖ Weights appear to be loaded.\n"
     ]
    }
   ],
   "source": [
    "# Check a specific weight to see if it's actually loaded or just random\n",
    "test_var = [v for v in tf.compat.v1.global_variables() if \"wd00\" in v.name][0]\n",
    "weight_values = sess.run(test_var)\n",
    "\n",
    "print(f\"Variable Name: {test_var.name}\")\n",
    "print(f\"Weight Mean: {np.mean(weight_values)}\")\n",
    "print(f\"Weight Max: {np.max(weight_values)}\")\n",
    "\n",
    "if np.abs(np.mean(weight_values)) < 1e-7:\n",
    "    print(\"‚ùå ERROR: Weights are all zeros or uninitialized!\")\n",
    "else:\n",
    "    print(\"‚úÖ Weights appear to be loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d06219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Fine-tuning on M4 Pro...\n",
      "  Step 20/200 | Current Loss: 0.42615\n",
      "  Step 40/200 | Current Loss: 0.15236\n",
      "  Step 60/200 | Current Loss: 0.18149\n",
      "  Step 80/200 | Current Loss: 0.13451\n",
      "  Step 100/200 | Current Loss: 0.10590\n",
      "  Step 120/200 | Current Loss: 0.13223\n",
      "  Step 140/200 | Current Loss: 0.14896\n",
      "  Step 160/200 | Current Loss: 0.39631\n",
      "  Step 180/200 | Current Loss: 0.53719\n",
      "  Step 200/200 | Current Loss: 0.27250\n",
      "‚úÖ Epoch 1 Complete | Avg Loss: 0.18967\n",
      "  Step 20/200 | Current Loss: 0.10546\n",
      "  Step 40/200 | Current Loss: 0.11678\n",
      "  Step 60/200 | Current Loss: 0.13960\n",
      "  Step 80/200 | Current Loss: 0.15170\n",
      "  Step 100/200 | Current Loss: 0.35908\n",
      "  Step 120/200 | Current Loss: 0.53401\n",
      "  Step 140/200 | Current Loss: 0.13568\n",
      "  Step 160/200 | Current Loss: 0.48854\n",
      "  Step 180/200 | Current Loss: 0.20769\n",
      "  Step 200/200 | Current Loss: 0.24869\n",
      "‚úÖ Epoch 2 Complete | Avg Loss: 0.17056\n",
      "  Step 20/200 | Current Loss: 0.15477\n",
      "  Step 40/200 | Current Loss: 0.71650\n",
      "  Step 60/200 | Current Loss: 0.51945\n",
      "  Step 80/200 | Current Loss: 0.17190\n",
      "  Step 100/200 | Current Loss: 0.10411\n",
      "  Step 120/200 | Current Loss: 0.09401\n",
      "  Step 140/200 | Current Loss: 0.07882\n",
      "  Step 160/200 | Current Loss: 0.08631\n",
      "  Step 180/200 | Current Loss: 0.14542\n",
      "  Step 200/200 | Current Loss: 0.14344\n",
      "‚úÖ Epoch 3 Complete | Avg Loss: 0.16733\n",
      "  Step 20/200 | Current Loss: 0.32721\n",
      "  Step 40/200 | Current Loss: 0.12291\n",
      "  Step 60/200 | Current Loss: 0.10715\n",
      "  Step 80/200 | Current Loss: 0.07545\n",
      "  Step 100/200 | Current Loss: 0.19014\n",
      "  Step 120/200 | Current Loss: 0.16353\n",
      "  Step 140/200 | Current Loss: 0.17719\n",
      "  Step 160/200 | Current Loss: 0.11749\n",
      "  Step 180/200 | Current Loss: 0.53274\n",
      "  Step 200/200 | Current Loss: 0.40874\n",
      "‚úÖ Epoch 4 Complete | Avg Loss: 0.17229\n",
      "  Step 20/200 | Current Loss: 0.11927\n",
      "  Step 40/200 | Current Loss: 0.10593\n",
      "  Step 60/200 | Current Loss: 0.09243\n",
      "  Step 80/200 | Current Loss: 0.20032\n",
      "  Step 100/200 | Current Loss: 0.17002\n",
      "  Step 120/200 | Current Loss: 0.20847\n",
      "  Step 140/200 | Current Loss: 0.11210\n",
      "  Step 160/200 | Current Loss: 0.14216\n",
      "  Step 180/200 | Current Loss: 0.18314\n",
      "  Step 200/200 | Current Loss: 0.36256\n",
      "‚úÖ Epoch 5 Complete | Avg Loss: 0.16904\n",
      "üíæ Model saved to ./finetuned_chair_with_masks_model_learning_rate_1e_4.cptk\n"
     ]
    }
   ],
   "source": [
    "# 1. Update the Placeholder to handle dynamic batch sizes\n",
    "# (If your real_model() fixed the batch at 1, we need to redefine img_ph)\n",
    "# Assuming img_ph was created inside real_model, ensure it supports batch size 4.\n",
    "\n",
    "# 2. Create a NEW saver for saving the WHOLE state (Model + Optimizer)\n",
    "# This is different from the restoration saver we used earlier\n",
    "final_saver = tf.compat.v1.train.Saver() \n",
    "\n",
    "print(\"üöÄ Starting Fine-tuning on M4 Pro...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        try:\n",
    "            batch_imgs, batch_gt, batch_masks = next(gen)\n",
    "            \n",
    "            # Run optimization with mask_ph\n",
    "            _, l = sess.run([optimizer, total_loss], feed_dict={\n",
    "                img_ph: batch_imgs,\n",
    "                gt_ph: batch_gt,\n",
    "                mask_ph: batch_masks\n",
    "            })\n",
    "            \n",
    "            epoch_loss += l\n",
    "            \n",
    "            if (step + 1) % 20 == 0:\n",
    "                print(f\"  Step {step+1}/{STEPS_PER_EPOCH} | Current Loss: {l:.5f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error at Step {step}: {e}\")\n",
    "            continue\n",
    "\n",
    "    avg_loss = epoch_loss / STEPS_PER_EPOCH\n",
    "    print(f\"‚úÖ Epoch {epoch+1} Complete | Avg Loss: {avg_loss:.5f}\")\n",
    "\n",
    "# 3. Save the result\n",
    "final_saver.save(sess, save_path)\n",
    "print(f\"üíæ Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7752c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def visualize_voxels(voxels):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Render the cubes (True values)\n",
    "    ax.voxels(voxels, edgecolor='k', facecolors='coral', alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z') \n",
    "    plt.title(\"Fine-tuned PSVH Chair Result\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af365bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model():\n",
    "    tf.reset_default_graph()\n",
    "    v_before, v_after, img_ph = real_model() # Define the \"map\"\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # 1. Initialize EVERYTHING (Sets the stage)\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    \n",
    "    # 2. Restore your FINE-TUNED weights (This is the important part)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, fine_tuned_model_path)\n",
    "    print(\"‚úÖ Fine-tuned weights are now active in the session!\")\n",
    "    return sess, v_after, img_ph\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psvh-finetuning (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
